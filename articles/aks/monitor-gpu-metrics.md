---
title: Monitor GPU metrics in Azure Kubernetes Service (AKS)
description: Learn how to monitor GPU metrics in Azure Kubernetes Service (AKS) using Azure Managed Prometheus and Grafana and the DCGM Exporter.
ms.topic: how-to
ms.service: azure-kubernetes-service
ms.date: 03/21/2025
author: schaffererin
ms.author: schaffererin
---

# Monitor GPU metrics in Azure Kubernetes Service (AKS) with Azure Managed Prometheus and Grafana and the DCGM Exporter

In this article, you learn how to monitor GPU metrics in Azure Kubernetes Service (AKS) using Azure Managed Prometheus and Grafana, along with the NVIDIA Data Center GPU Manager (DCGM) Exporter.

## Prerequisites

- [An AKS cluster with GPU-enabled node pool(s)](./gpu-cluster.md).
- [NVIDIA Kubernetes device plugin installed on your GPU node pool](./gpu-cluster.md#options-for-using-nvidia-gpus).
- A [sample GPU workload](./gpu-cluster.md#run-a-gpu-enabled-workload) deployed to your node pool.
- [Azure Managed Prometheus and Grafana enabled on your AKS cluster](/azure/azure-monitor/containers/kubernetes-monitoring-enable).
- [An Azure Container Registry (ACR) integrated with your AKS cluster](./cluster-container-registry-integration.md).
- [Helm version 3 or above installed on your cluster](https://helm.sh/docs/intro/install/).

## Install NVIDIA DCGM Exporter

NVIDIA DCGM Exporter collects and exports GPU metrics. It runs as a pod on your AKS cluster and gathers metrics such as utilization, memory usage, temperature, and power consumption. For more information, see the [NVIDIA DCGM Exporter documentation](https://docs.nvidia.com/datacenter/cloud-native/gpu-telemetry/latest/dcgm-exporter.html).

[!INCLUDE [open source disclaimer](./includes/open-source-disclaimer.md)]

Follow the steps in [Quickstart on Kubernetes](https://github.com/NVIDIA/dcgm-exporter?tab=readme-ov-file#quickstart-on-kubernetes) to install the DCGM Exporter using Helm. You might need to update the default configurations of NVIDIA DCGM Exporter to use the Azure Managed Prometheus custom resource definition (CRD) using the steps in [Update default configurations for the DCGM Exporter](#update-default-configurations-for-the-dcgm-exporter).

### Update default configurations for the DCGM Exporter

1. Clone the [NVIDIA/dcgm-exporter GitHub repository](https://github.com/NVIDIA/dcgm-exporter).

    ```bash
    git clone https://github.com/NVIDIA/dcgm-exporter.git
    ```

2. Navigate to the [`templates` folder](https://github.com/NVIDIA/dcgm-exporter/tree/main/deployment/templates) in the cloned repository.

    ```bash
    cd dcgm-exporter/deployment/templates
    ```

3. Open the `service-monitor.yaml` and update the `apiVersion` key to `azmonitoring.coreos.com/v1`. This change allows the DCGM Exporter to use the Azure Managed Prometheus CRD.

    ```yml
    apiVersion: azmonitoring.coreos.com/v1
    ```

4. Open the `values.yaml` and update the tolerations and node selector tags using the following code snippet:

    ```yml
    nodeSelector:
      accelerator: nvidia

    tolerations:
    - key: "sku"
      operator: "Equal"
      value: "gpu"
      effect: "NoSchedule"
    ```

## Push the Helm chart to your ACR

1. Navigate to the `deployment` folder of the cloned repository, and then package the Helm chart using the `helm package` command.

    ```bash
    helm package .
    ```

2. Authenticate Helm with your ACR using the `helm registry login` command. Replace `<acr_url>`, `<user_name>`, and `<password>` with your ACR details. For more detailed instructions, see [Authenticate Helm with Azure Container Registry](/azure/container-registry/container-registry-helm-repos#authenticate-with-the-registry).

    ```bash
    helm registry login <acr_url> --username <user_name> --password <password>
    ```

3. Push the Helm chart to your ACR using the `helm push` command. Replace `<acr_url>` with your ACR URL.

    ```bash
    helm push dcgm-exporter-3.4.2.tgz oci://<acr_url>/helm
    ```

4. Install the Helm chart on your AKS cluster using the `helm install` command. Replace `<acr_url>` with your ACR URL.

    ```bash
    helm install dcgm-nvidia oci://<acr_url>/helm/dcgm-exporter -n gpu-resources
    ```

5. Check the installation on your AKS cluster using the `helm list` command.

    ```bash
    helm list -n gpu-resources
    ```

6. Verify the DCGM Exporter is running on your GPU node pool using the `kubectl get pods` and `kubectl get ds` commands.

    ```bash
    kubectl get pods -n gpu-resources
    kubectl get ds -n gpu-resources
    ```

## Export GPU metrics and configure Grafana dashboard

Once NVIDIA DCGM Exporter is successfully deployed to your GPU node pool, you need to export the GPU metrics generated by the workload to Azure Managed Prometheus by deploying a PodMonitor resource.

1. Create a file named `pod-monitor.yaml` and add the following configuration to it:

    ```yml
    apiVersion: azmonitoring.coreos.com/v1
    kind: PodMonitor
    metadata:
      name: nvidia-dcgm-exporter
      labels:
        app.kubernetes.io/name: nvidia-dcgm-exporter
    spec:
      selector:
        matchLabels:
          app.kubernetes.io/name: nvidia-dcgm-exporter
      podMetricsEndpoints:
      - port: metrics
        interval: 30s
      podTargetLabels:
    ```

2. Apply the PodMonitor configuration to your AKS cluster using the `kubectl apply` command.

    ```bash
    kubectl apply -f pod-monitor.yaml -n gpu-resources
    ```

3. Verify the PodMonitor was successfully created using the `kubectl get podmonitor` command.

    ```bash
    kubectl get podmonitor -n gpu-resources
    ```

4. In the [Azure portal](https://portal.azure.com), navigate to the **Metrics** section of your Azure Monitor workspace.
5. Import the [dcgm-exporter-dashboard.json](https://github.com/NVIDIA/dcgm-exporter/blob/main/grafana/dcgm-exporter-dashboard.json) into your Managed Grafana instance using the steps in [Create a dashboard in Azure Managed Grafana](/azure/managed-grafana/how-to-create-dashboard). After importing the JSON, the dashboard displaying GPU metrics should be visible in your Grafana instance.

## Next steps

- Deploy a [multi-instance GPU (MIG)](./gpu-multi-instance.md) workload on AKS.
- Explore the [AI toolchain operator add-on (preview)](./ai-toolchain-operator.md) for AI inferencing and fine-tuning.
- Learn more about [Ray clusters on AKS](./ray-overview.md).
